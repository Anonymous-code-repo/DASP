<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" class="gr__shape2prog_csail_mit_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

              <meta name="viewport" content="width=device-width, initial-scale=1">    <link rel="shortcut icon" href="http://shape2prog.csail.mit.edu/images/favicon.ico">
        <meta name="description" content="Counterfactual Data-Augmented Sequential Recommendation">
        <meta name="keywords" content="Counterfactual Data-Augmented, Sequential Recommendation">

        <title>Sequential Recommendation</title>
        <link rel="stylesheet" href="asset/font.css">
        <link rel="stylesheet" href="asset/main.css">

    </head>

    <body data-gr-c-s-loaded="true">

        <div class="outercontainer">
            <div class="container">

                <div class="content project_title">
                    <h1>Generative Sequential Recommendation</h1>
                </div>

                <div class="content project_headline">
                    <center><h2>
                      <font size="3">Anonymous Author</font>&nbsp;&nbsp;
                   
                </div>


                


                <div class="content">
                    <div class="text">
                        <h1>1. Abstract</h1>
                        <p><font size=3>Sequential recommendation has recently attracted increasing attention from the academic and industry communities.
                            Previous models mostly design various neural models to introduce different inductive biases on user sequential behaviors to fit the training data.
                            However, the training data itself can be quite sparse in practical recommender systems, especially for the sequential behaviors, which makes it hard to learn reliable models.
                            In order to solve this problem, in this paper, we propose a novel generative session-based recommendation framework.
                            Our key idea is to simultaneously train the recommendation model and generate user sequential behaviors to compensate existing training data.
                            In order to generate high quality samples, we consider two aspects:
                            (1) <b>the rationality as a sequence of user behaviors</b>, and (2) <b>the informativeness for training the target model</b>.
                            To satisfy these requirements, we design a doubly adversarial network.
                            The first adversarial module aims to make the generated samples conform to the underlying patterns of the observed data.
                            The second adversarial module is targeted at widening the model experiences by the generated samples.
                            In our model, the training samples are generated based on a reinforcement learning strategy, where the agent is required to simultaneously mimic the real user behaviors and maximize the loss of the target model. 
                            In order to stable the training process, we introduce a self-paced regularizer to learn the agent in an easy-to-hard manner. 
                            We conduct extensive experiments based on three real-world datasets to demonstrate the promises and superiorities of our model. </font></p>
                    </div>
                </div>

                <div class="content">
                    <div class="text">
                        <h1>2. Illustration of Our Framework</h1>
                        <div class="content project_headline">
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/intro.png" alt="Intro" style="margin:auto;max-width:100%">
                        </div>
                        <div class="text">
                            <p><font size=3>(a) The general framework of our model. There are three components.
                                Along the red dotted line is the rationality module, which aims to generate reasonable user behavior sequences.
                                The blue solid line indicates the informativeness module, which tries to make the generated sequence informative. 
                                The dotted purple square means the sequence in our model is generated in an "easy-to-hard" manner.</font></p>
                            <p><font size=3>b) The architecture of the discriminator and agent.</font></p>
                            <p><font size=3>(c) The training process of our framework.</font></p>
                            <p><font size=3>The target sequential recommender model is firstly pre-trained based on the original dataset, and then the agent is optimized and leveraged to generate new samples. At last, the target model is retrained based on union between the generated and original datasets.</font></p>
                            </font></p>
                        </div>
						<div class="content">
						<h3>Contributions</h3>
                            <p><ul class="download">
							<font size=3>
                            <li>In this paper, we propose to improve sequential recommendation from the perspective of enriching the training data, which is orthogonal with existing model-oriented studies.</li>
							<li>For generating reasonable and informative sequences, we design a <u><b>d</b></u>oubly <u><b>a</b></u>dversarial neural network, and further improve it with a <u><b>s</b></u>elf-<u><b>p</b></u>aced regularizer (called <b>DASP</b> for short).</li>
							<li>We conduct extensive experiments based on real-world datasets to evaluate our model.</li>
                            </font>
                        </ul></p>
                        </div>
                    </div>
                    </div>
                </div>
                <div class="content">
                    <div class="text">
                        <h1>3. Main Results</h1>
                    </div>

                    <div class="content project_headline">
					<div class="text">
                            <p><font size=3>Table 1: Overall comparison between the baselines and our models.</font></p>
                        </div>
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/DASP_result_1.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        
                    </div>
					
                </div>
				<div class="content">
                    <div class="text">
                        <h1>4. Code and Datasets</h1>

						<h2> 4.1 Code <a href="https://drive.google.com/drive/folders/1QfHFYgKeVitJKOqkH7HWsIL4RjZZbAeI?usp=sharing">[link:Google Driver]</font></a></h2>
						
						<div class="content project_headline">
						<div class="text">
                            <p><font size=3>Table 2: Structure of the code files [main program].</font></p>
                        </div>
						<div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/code1.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
					
                        <div class="img" style="text-align:center">
						<div class="text">
                            <p><font size=3>Table 3: Structure of the code files [utils].</font></p>
                        </div>
                            <img class="img_responsive" src="asset/code2.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        
                        </div>
                        <h2>4.2 Datasets <a href="https://drive.google.com/drive/folders/1yoH_YI4o5knC8hxlhJZmhorvl_NIrCiU?usp=sharing">[link:Google Driver]</a></font></h2>
						<div class="content project_headline">
						<div class="text">
                            <p><font size=3>Table 4: Statistics of the datasets used in our experiments.</font></p>
                        </div>
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/dataset.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        
                        </div>
                    </div>
                </div>


                <div class="content">
                    <div class="text">
                        <h1>5. Usage</h1>
						<p> <font size=4>5.1. Download the code</font></p>
						<p> <font size=4>5.2. Download the dataset, and put it into dataset/dataset name/ folder.</font></p>
						<p> <font size=4>5.3. Pre-train the sampler and anchor model.</font></p>
						<font size=3>
                        <p>Before you can run our program, you should run run_test_example.py or run_hyper.py to train Sampler model and Anchor model firstly. we provided source code for three models NARM, STAMP and SASRec.</p>
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/run1.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        <p>We also provide automatic parameter tuning tools. In hyper.test file,setting up the range of tuning parameter such as:</p>
						<div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/run2.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
						<p>then run run_hyper.py</p>
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/run3.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        <p>you should also save the trained model named Model name-dataset name.pth,in which the model name is one of the three model NARM, STAMP and SASRec,and put it in the folder savedTrainer/. we have trained some model as examples which could be used to train our method directly.</p>
						<p> <font size=4>5.4. Run our framework</font></p>
						<p>Run main.py file to train our model. You can configure some training parameters through the command line</p>
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/run4.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
						<p>where --learning denotes one of our methods 'Heuristic', 'Learning' and 'AD' representing heuristic, data-and model-oriented methods respectively. --sample denotes the number of sample,--kappa denotes the confidence parameter, --iter denotes the iteration number, --tao denotes the temperature parameter, --index denotes the intervention index from back to front, we remove the negative sign from the value 
						for the facilitation of the experiment</p>
						</font>
                    </div>
                </div>
               
                <div class="content">
                    <div class="text">
                        <h1>6. Detailed parameter search ranges</h1>
						
						<div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/range.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                    </div>
                </div>


                <div class="content">
                    <div class="text">
                        <h1>7. Runtime Environment</h1>
						<ul class="download">
						<font size=3>
                            <li><p>System:Linux dell-PowerEdge-R730</p></li>
							<li><p>CPU: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz</p></li>
							<li><p>CPU-Memory:25G</p></li>
							<li><p>GPU:NVIDIA Corporation GV100 [TITAN V] (rev a1)</p></li>
                            <li><p>GPU-Memory:12G</p></li>
							<li><p>Pytorch: 1.7.0</p></li>
							<li><p>CUDA:10.1</p></li>
						</font>
                        </ul>
						
                    </div>
                </div>

<div id="download_plus_animation"></div></body></html>


